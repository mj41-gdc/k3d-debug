#Start_logs: 2021-04-29 14:20:44.088216641+02:00
2021-04-29T12:20:20.560133935Z  time="2021-04-29T12:20:20.559597131Z" level=info msg="Starting k3s v1.20.6+k3s1 (8d043282)"
2021-04-29T12:20:20.575927418Z  time="2021-04-29T12:20:20.575692959Z" level=info msg="Configuring sqlite3 database connection pooling: maxIdleConns=2, maxOpenConns=0, connMaxLifetime=0s"
2021-04-29T12:20:20.575978403Z  time="2021-04-29T12:20:20.575762522Z" level=info msg="Configuring database table schema and indexes, this may take a moment..."
2021-04-29T12:20:20.585075237Z  time="2021-04-29T12:20:20.584442190Z" level=info msg="Database tables and indexes are up to date"
2021-04-29T12:20:20.586555187Z  time="2021-04-29T12:20:20.586337769Z" level=info msg="Kine listening on unix://kine.sock"
2021-04-29T12:20:20.609256659Z  time="2021-04-29T12:20:20.608860097Z" level=info msg="certificate CN=system:admin,O=system:masters signed by CN=k3s-client-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.610183321Z  time="2021-04-29T12:20:20.609993282Z" level=info msg="certificate CN=system:kube-controller-manager signed by CN=k3s-client-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.611398710Z  time="2021-04-29T12:20:20.611226410Z" level=info msg="certificate CN=system:kube-scheduler signed by CN=k3s-client-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.612464776Z  time="2021-04-29T12:20:20.612297784Z" level=info msg="certificate CN=kube-apiserver signed by CN=k3s-client-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.613521693Z  time="2021-04-29T12:20:20.613355260Z" level=info msg="certificate CN=system:kube-proxy signed by CN=k3s-client-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.614703208Z  time="2021-04-29T12:20:20.614532794Z" level=info msg="certificate CN=system:k3s-controller signed by CN=k3s-client-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.616081049Z  time="2021-04-29T12:20:20.615827453Z" level=info msg="certificate CN=cloud-controller-manager signed by CN=k3s-client-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.618057783Z  time="2021-04-29T12:20:20.617538579Z" level=info msg="certificate CN=kube-apiserver signed by CN=k3s-server-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.619723722Z  time="2021-04-29T12:20:20.619457903Z" level=info msg="certificate CN=system:auth-proxy signed by CN=k3s-request-header-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.621337209Z  time="2021-04-29T12:20:20.621091714Z" level=info msg="certificate CN=etcd-server signed by CN=etcd-server-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.622318068Z  time="2021-04-29T12:20:20.622064263Z" level=info msg="certificate CN=etcd-client signed by CN=etcd-server-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.623999232Z  time="2021-04-29T12:20:20.623788938Z" level=info msg="certificate CN=etcd-peer signed by CN=etcd-peer-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.826415024Z  time="2021-04-29T12:20:20.826188178Z" level=info msg="certificate CN=k3s,O=k3s signed by CN=k3s-server-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:20 +0000 UTC"
2021-04-29T12:20:20.826919213Z  time="2021-04-29T12:20:20.826708430Z" level=info msg="Active TLS secret  (ver=) (count 8): map[listener.cattle.io/cn-0.0.0.0:0.0.0.0 listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.27.0.2:172.27.0.2 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=FEA5BA991F79AE1DDF81C48B70DD34E159778B6F]"
2021-04-29T12:20:20.830508387Z  time="2021-04-29T12:20:20.830217076Z" level=info msg="Running kube-apiserver --advertise-port=6443 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,k3s --authorization-mode=Node,RBAC --bind-address=127.0.0.1 --cert-dir=/var/lib/rancher/k3s/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/k3s/server/tls/client-ca.crt --enable-admission-plugins=NodeRestriction --etcd-servers=unix://kine.sock --feature-gates=ServiceAccountIssuerDiscovery=false --insecure-port=0 --kubelet-certificate-authority=/var/lib/rancher/k3s/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/k3s/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/k3s/server/tls/client-kube-apiserver.key --profiling=false --proxy-client-cert-file=/var/lib/rancher/k3s/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/k3s/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/k3s/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6444 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/k3s/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/k3s/server/tls/service.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.crt --tls-private-key-file=/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.key"
2021-04-29T12:20:20.831838106Z  Flag --insecure-port has been deprecated, This flag has no effect now and will be removed in v1.24.
2021-04-29T12:20:20.832317152Z  I0429 12:20:20.832217       7 server.go:659] external host was not specified, using 172.27.0.2
2021-04-29T12:20:20.832460816Z  I0429 12:20:20.832383       7 server.go:196] Version: v1.20.6+k3s1
2021-04-29T12:20:21.099810137Z  I0429 12:20:21.099596       7 shared_informer.go:240] Waiting for caches to sync for node_authorizer
2021-04-29T12:20:21.100605496Z  I0429 12:20:21.100403       7 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
2021-04-29T12:20:21.100641744Z  I0429 12:20:21.100422       7 plugins.go:161] Loaded 10 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
2021-04-29T12:20:21.102543469Z  I0429 12:20:21.102309       7 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
2021-04-29T12:20:21.102595640Z  I0429 12:20:21.102351       7 plugins.go:161] Loaded 10 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
2021-04-29T12:20:21.132337384Z  I0429 12:20:21.132069       7 instance.go:289] Using reconciler: lease
2021-04-29T12:20:21.170588103Z  I0429 12:20:21.170375       7 rest.go:131] the default service ipfamily for this cluster is: IPv4
2021-04-29T12:20:21.444817267Z  W0429 12:20:21.444316       7 genericapiserver.go:425] Skipping API batch/v2alpha1 because it has no resources.
2021-04-29T12:20:21.453680620Z  W0429 12:20:21.453285       7 genericapiserver.go:425] Skipping API discovery.k8s.io/v1alpha1 because it has no resources.
2021-04-29T12:20:21.462391089Z  W0429 12:20:21.461935       7 genericapiserver.go:425] Skipping API node.k8s.io/v1alpha1 because it has no resources.
2021-04-29T12:20:21.468903565Z  W0429 12:20:21.468540       7 genericapiserver.go:425] Skipping API rbac.authorization.k8s.io/v1alpha1 because it has no resources.
2021-04-29T12:20:21.472025008Z  W0429 12:20:21.471642       7 genericapiserver.go:425] Skipping API scheduling.k8s.io/v1alpha1 because it has no resources.
2021-04-29T12:20:21.476706299Z  W0429 12:20:21.476092       7 genericapiserver.go:425] Skipping API storage.k8s.io/v1alpha1 because it has no resources.
2021-04-29T12:20:21.478777949Z  W0429 12:20:21.478232       7 genericapiserver.go:425] Skipping API flowcontrol.apiserver.k8s.io/v1alpha1 because it has no resources.
2021-04-29T12:20:21.482507994Z  W0429 12:20:21.482063       7 genericapiserver.go:425] Skipping API apps/v1beta2 because it has no resources.
2021-04-29T12:20:21.482555486Z  W0429 12:20:21.482090       7 genericapiserver.go:425] Skipping API apps/v1beta1 because it has no resources.
2021-04-29T12:20:21.489765682Z  I0429 12:20:21.489548       7 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
2021-04-29T12:20:21.489810171Z  I0429 12:20:21.489569       7 plugins.go:161] Loaded 10 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
2021-04-29T12:20:21.506216936Z  time="2021-04-29T12:20:21.505985969Z" level=info msg="Running kube-scheduler --address=127.0.0.1 --bind-address=127.0.0.1 --kubeconfig=/var/lib/rancher/k3s/server/cred/scheduler.kubeconfig --leader-elect=false --port=10251 --profiling=false --secure-port=0"
2021-04-29T12:20:21.506434284Z  time="2021-04-29T12:20:21.506142554Z" level=info msg="Waiting for API server to become available"
2021-04-29T12:20:21.507367231Z  time="2021-04-29T12:20:21.507132353Z" level=info msg="Running kube-controller-manager --address=127.0.0.1 --allocate-node-cidrs=true --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-cert-file=/var/lib/rancher/k3s/server/tls/client-ca.crt --cluster-signing-key-file=/var/lib/rancher/k3s/server/tls/client-ca.key --configure-cloud-routes=false --controllers=*,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/k3s/server/cred/controller.kubeconfig --leader-elect=false --port=10252 --profiling=false --root-ca-file=/var/lib/rancher/k3s/server/tls/server-ca.crt --secure-port=0 --service-account-private-key-file=/var/lib/rancher/k3s/server/tls/service.key --use-service-account-credentials=true"
2021-04-29T12:20:21.509567530Z  time="2021-04-29T12:20:21.509352976Z" level=info msg="Node token is available at /var/lib/rancher/k3s/server/token"
2021-04-29T12:20:21.509608946Z  time="2021-04-29T12:20:21.509514031Z" level=info msg="To join node to cluster: k3s agent -s https://172.27.0.2:6443 -t ${NODE_TOKEN}"
2021-04-29T12:20:21.511490766Z  time="2021-04-29T12:20:21.511308129Z" level=info msg="Wrote kubeconfig /output/kubeconfig.yaml"
2021-04-29T12:20:21.512132752Z  time="2021-04-29T12:20:21.511861905Z" level=info msg="Run: k3s kubectl"
2021-04-29T12:20:21.512547264Z  time="2021-04-29T12:20:21.512359878Z" level=info msg="Module overlay was already loaded"
2021-04-29T12:20:21.512578204Z  time="2021-04-29T12:20:21.512401853Z" level=info msg="Module nf_conntrack was already loaded"
2021-04-29T12:20:21.512582953Z  time="2021-04-29T12:20:21.512421828Z" level=info msg="Module br_netfilter was already loaded"
2021-04-29T12:20:21.512587353Z  time="2021-04-29T12:20:21.512440545Z" level=info msg="Module iptable_nat was already loaded"
2021-04-29T12:20:21.563331456Z  time="2021-04-29T12:20:21.563086940Z" level=info msg="Cluster-Http-Server 2021/04/29 12:20:21 http: TLS handshake error from 127.0.0.1:36628: remote error: tls: bad certificate"
2021-04-29T12:20:21.570448972Z  time="2021-04-29T12:20:21.570292526Z" level=info msg="Cluster-Http-Server 2021/04/29 12:20:21 http: TLS handshake error from 127.0.0.1:36634: remote error: tls: bad certificate"
2021-04-29T12:20:21.585043759Z  time="2021-04-29T12:20:21.584819008Z" level=info msg="certificate CN=k3d-default-server-0 signed by CN=k3s-server-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:21 +0000 UTC"
2021-04-29T12:20:21.589665405Z  time="2021-04-29T12:20:21.589488146Z" level=info msg="certificate CN=system:node:k3d-default-server-0,O=system:nodes signed by CN=k3s-client-ca@1619698820: notBefore=2021-04-29 12:20:20 +0000 UTC notAfter=2022-04-29 12:20:21 +0000 UTC"
2021-04-29T12:20:21.671830670Z  time="2021-04-29T12:20:21.671627290Z" level=info msg="Logging containerd to /var/lib/rancher/k3s/agent/containerd/containerd.log"
2021-04-29T12:20:21.671894575Z  time="2021-04-29T12:20:21.671815793Z" level=info msg="Running containerd -c /var/lib/rancher/k3s/agent/etc/containerd/config.toml -a /run/k3s/containerd/containerd.sock --state /run/k3s/containerd --root /var/lib/rancher/k3s/agent/containerd"
2021-04-29T12:20:22.675299177Z  time="2021-04-29T12:20:22.675090280Z" level=info msg="Containerd is now running"
2021-04-29T12:20:22.682862843Z  time="2021-04-29T12:20:22.682651292Z" level=info msg="Connecting to proxy" url="wss://127.0.0.1:6443/v1-k3s/connect"
2021-04-29T12:20:22.686189760Z  time="2021-04-29T12:20:22.686033664Z" level=info msg="Handling backend connection request [k3d-default-server-0]"
2021-04-29T12:20:22.687922607Z  time="2021-04-29T12:20:22.687708123Z" level=info msg="Running kubelet --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=cgroupfs --client-ca-file=/var/lib/rancher/k3s/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --cni-bin-dir=/bin --cni-conf-dir=/var/lib/rancher/k3s/agent/etc/cni/net.d --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --container-runtime=remote --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available<5%,nodefs.available<5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --healthz-bind-address=127.0.0.1 --hostname-override=k3d-default-server-0 --kubeconfig=/var/lib/rancher/k3s/agent/kubelet.kubeconfig --kubelet-cgroups=/k3s --node-labels= --pod-manifest-path=/var/lib/rancher/k3s/agent/pod-manifests --read-only-port=0 --resolv-conf=/tmp/k3s-resolv.conf --runtime-cgroups=/k3s --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/k3s/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/k3s/agent/serving-kubelet.key"
2021-04-29T12:20:22.688899555Z  time="2021-04-29T12:20:22.688714265Z" level=info msg="Running kube-proxy --cluster-cidr=10.42.0.0/16 --healthz-bind-address=127.0.0.1 --hostname-override=k3d-default-server-0 --kubeconfig=/var/lib/rancher/k3s/agent/kubeproxy.kubeconfig --proxy-mode=iptables"
2021-04-29T12:20:22.688947187Z  Flag --cloud-provider has been deprecated, will be removed in 1.23, in favor of removing cloud provider code from Kubelet.
2021-04-29T12:20:22.689000617Z  Flag --containerd has been deprecated, This is a cadvisor flag that was mistakenly registered with the Kubelet. Due to legacy concerns, it will follow the standard CLI deprecation timeline before being removed.
2021-04-29T12:20:22.689324892Z  W0429 12:20:22.689178       7 server.go:226] WARNING: all flags other than --config, --write-config-to, and --cleanup are deprecated. Please begin using a config file ASAP.
2021-04-29T12:20:22.689615854Z  I0429 12:20:22.689462       7 server.go:412] Version: v1.20.6+k3s1
2021-04-29T12:20:22.690155242Z  W0429 12:20:22.689977       7 proxier.go:651] Failed to read file /lib/modules/5.11.15-200.fc33.x86_64/modules.builtin with error open /lib/modules/5.11.15-200.fc33.x86_64/modules.builtin: no such file or directory. You can ignore this message when kube-proxy is running inside container without mounting /lib/modules
2021-04-29T12:20:22.691007383Z  W0429 12:20:22.690849       7 proxier.go:661] Failed to load kernel module ip_vs with modprobe. You can ignore this message when kube-proxy is running inside container without mounting /lib/modules
2021-04-29T12:20:22.691695954Z  W0429 12:20:22.691535       7 proxier.go:661] Failed to load kernel module ip_vs_rr with modprobe. You can ignore this message when kube-proxy is running inside container without mounting /lib/modules
2021-04-29T12:20:22.692196720Z  W0429 12:20:22.692095       7 proxier.go:661] Failed to load kernel module ip_vs_wrr with modprobe. You can ignore this message when kube-proxy is running inside container without mounting /lib/modules
2021-04-29T12:20:22.693021064Z  W0429 12:20:22.692866       7 proxier.go:661] Failed to load kernel module ip_vs_sh with modprobe. You can ignore this message when kube-proxy is running inside container without mounting /lib/modules
2021-04-29T12:20:22.693732613Z  W0429 12:20:22.693564       7 proxier.go:661] Failed to load kernel module nf_conntrack with modprobe. You can ignore this message when kube-proxy is running inside container without mounting /lib/modules
2021-04-29T12:20:22.698014409Z  time="2021-04-29T12:20:22.697805861Z" level=info msg="Waiting for node k3d-default-server-0: nodes \"k3d-default-server-0\" not found"
2021-04-29T12:20:22.701050715Z  E0429 12:20:22.700840       7 node.go:161] Failed to retrieve node info: nodes "k3d-default-server-0" is forbidden: User "system:kube-proxy" cannot get resource "nodes" in API group "" at the cluster scope
2021-04-29T12:20:22.713208230Z  I0429 12:20:22.713054       7 dynamic_cafile_content.go:167] Starting client-ca-bundle::/var/lib/rancher/k3s/agent/client-ca.crt
2021-04-29T12:20:22.713244617Z  W0429 12:20:22.713056       7 manager.go:159] Cannot detect current cgroup on cgroup v2
2021-04-29T12:20:22.977658763Z  I0429 12:20:22.977545       7 dynamic_cafile_content.go:167] Starting request-header::/var/lib/rancher/k3s/server/tls/request-header-ca.crt
2021-04-29T12:20:22.977694103Z  I0429 12:20:22.977551       7 dynamic_cafile_content.go:167] Starting client-ca-bundle::/var/lib/rancher/k3s/server/tls/client-ca.crt
2021-04-29T12:20:22.977822193Z  I0429 12:20:22.977710       7 dynamic_serving_content.go:130] Starting serving-cert::/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.crt::/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.key
2021-04-29T12:20:22.978033255Z  I0429 12:20:22.977989       7 secure_serving.go:197] Serving securely on 127.0.0.1:6444
2021-04-29T12:20:22.978061751Z  I0429 12:20:22.978036       7 controller.go:83] Starting OpenAPI AggregationController
2021-04-29T12:20:22.978178387Z  I0429 12:20:22.978057       7 tlsconfig.go:240] Starting DynamicServingCertificateController
2021-04-29T12:20:22.978206533Z  I0429 12:20:22.978089       7 apf_controller.go:261] Starting API Priority and Fairness config controller
2021-04-29T12:20:22.978383722Z  I0429 12:20:22.978278       7 dynamic_serving_content.go:130] Starting aggregator-proxy-cert::/var/lib/rancher/k3s/server/tls/client-auth-proxy.crt::/var/lib/rancher/k3s/server/tls/client-auth-proxy.key
2021-04-29T12:20:22.978421297Z  I0429 12:20:22.978295       7 apiservice_controller.go:97] Starting APIServiceRegistrationController
2021-04-29T12:20:22.978431982Z  I0429 12:20:22.978312       7 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
2021-04-29T12:20:22.978478637Z  I0429 12:20:22.978393       7 customresource_discovery_controller.go:209] Starting DiscoveryController
2021-04-29T12:20:22.978500637Z  I0429 12:20:22.978462       7 controller.go:86] Starting OpenAPI controller
2021-04-29T12:20:22.978523964Z  I0429 12:20:22.978492       7 naming_controller.go:291] Starting NamingConditionController
2021-04-29T12:20:22.978543450Z  I0429 12:20:22.978522       7 establishing_controller.go:76] Starting EstablishingController
2021-04-29T12:20:22.978580606Z  I0429 12:20:22.978535       7 crd_finalizer.go:266] Starting CRDFinalizer
2021-04-29T12:20:22.978673286Z  I0429 12:20:22.978564       7 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
2021-04-29T12:20:22.978699128Z  I0429 12:20:22.978582       7 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
2021-04-29T12:20:22.978722036Z  I0429 12:20:22.978664       7 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
2021-04-29T12:20:22.978731953Z  I0429 12:20:22.978674       7 shared_informer.go:240] Waiting for caches to sync for cluster_authentication_trust_controller
2021-04-29T12:20:22.978741452Z  I0429 12:20:22.978690       7 dynamic_cafile_content.go:167] Starting client-ca-bundle::/var/lib/rancher/k3s/server/tls/client-ca.crt
2021-04-29T12:20:22.978751579Z  I0429 12:20:22.978721       7 dynamic_cafile_content.go:167] Starting request-header::/var/lib/rancher/k3s/server/tls/request-header-ca.crt
2021-04-29T12:20:22.980140873Z  I0429 12:20:22.980009       7 available_controller.go:475] Starting AvailableConditionController
2021-04-29T12:20:22.980204499Z  I0429 12:20:22.980128       7 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
2021-04-29T12:20:22.980246404Z  I0429 12:20:22.980190       7 autoregister_controller.go:141] Starting autoregister controller
2021-04-29T12:20:22.980273643Z  I0429 12:20:22.980239       7 cache.go:32] Waiting for caches to sync for autoregister controller
2021-04-29T12:20:22.980823438Z  I0429 12:20:22.980772       7 crdregistration_controller.go:111] Starting crd-autoregister controller
2021-04-29T12:20:22.980859686Z  I0429 12:20:22.980833       7 shared_informer.go:240] Waiting for caches to sync for crd-autoregister
2021-04-29T12:20:22.983333415Z  time="2021-04-29T12:20:22.983216919Z" level=info msg="Waiting for cloudcontroller rbac role to be created"
2021-04-29T12:20:23.000643445Z  I0429 12:20:23.000508       7 shared_informer.go:247] Caches are synced for node_authorizer 
2021-04-29T12:20:23.078575943Z  I0429 12:20:23.078337       7 apf_controller.go:266] Running API Priority and Fairness config worker
2021-04-29T12:20:23.078620851Z  I0429 12:20:23.078401       7 cache.go:39] Caches are synced for APIServiceRegistrationController controller
2021-04-29T12:20:23.078943381Z  I0429 12:20:23.078729       7 shared_informer.go:247] Caches are synced for cluster_authentication_trust_controller 
2021-04-29T12:20:23.080548836Z  I0429 12:20:23.080305       7 cache.go:39] Caches are synced for AvailableConditionController controller
2021-04-29T12:20:23.080602614Z  I0429 12:20:23.080410       7 cache.go:39] Caches are synced for autoregister controller
2021-04-29T12:20:23.081068599Z  I0429 12:20:23.080920       7 shared_informer.go:247] Caches are synced for crd-autoregister 
2021-04-29T12:20:23.083833080Z  I0429 12:20:23.083620       7 controller.go:609] quota admission added evaluator for: namespaces
2021-04-29T12:20:23.118828260Z  E0429 12:20:23.118660       7 controller.go:151] Unable to perform initial Kubernetes service initialization: Service "kubernetes" is invalid: spec.clusterIPs: Invalid value: []string{"10.43.0.1"}: failed to allocated ip:10.43.0.1 with error:cannot allocate resources of type serviceipallocations at this time
2021-04-29T12:20:23.119722166Z  E0429 12:20:23.119566       7 controller.go:156] Unable to remove old endpoints from kubernetes service: StorageError: key not found, Code: 1, Key: /registry/masterleases/172.27.0.2, ResourceVersion: 0, AdditionalErrorMsg: 
2021-04-29T12:20:23.904188134Z  E0429 12:20:23.903978       7 node.go:161] Failed to retrieve node info: nodes "k3d-default-server-0" is forbidden: User "system:kube-proxy" cannot get resource "nodes" in API group "" at the cluster scope
2021-04-29T12:20:23.978464409Z  I0429 12:20:23.978170       7 controller.go:132] OpenAPI AggregationController: action for item : Nothing (removed from the queue).
2021-04-29T12:20:23.978524962Z  I0429 12:20:23.978230       7 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
2021-04-29T12:20:23.988072347Z  I0429 12:20:23.987842       7 storage_scheduling.go:132] created PriorityClass system-node-critical with value 2000001000
2021-04-29T12:20:23.995412309Z  I0429 12:20:23.995152       7 storage_scheduling.go:132] created PriorityClass system-cluster-critical with value 2000000000
2021-04-29T12:20:23.995460011Z  I0429 12:20:23.995192       7 storage_scheduling.go:148] all system priority classes are created successfully or already exist.
2021-04-29T12:20:24.707077550Z  time="2021-04-29T12:20:24.706855453Z" level=info msg="Waiting for node k3d-default-server-0: nodes \"k3d-default-server-0\" not found"
2021-04-29T12:20:24.743839240Z  I0429 12:20:24.743611       7 controller.go:609] quota admission added evaluator for: roles.rbac.authorization.k8s.io
2021-04-29T12:20:24.811420474Z  I0429 12:20:24.811184       7 controller.go:609] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
2021-04-29T12:20:24.963544459Z  W0429 12:20:24.963342       7 lease.go:233] Resetting endpoints for master service "kubernetes" to [172.27.0.2]
2021-04-29T12:20:24.965476914Z  I0429 12:20:24.965301       7 controller.go:609] quota admission added evaluator for: endpoints
2021-04-29T12:20:24.972873727Z  I0429 12:20:24.972644       7 controller.go:609] quota admission added evaluator for: endpointslices.discovery.k8s.io
2021-04-29T12:20:24.986748933Z  time="2021-04-29T12:20:24.986545344Z" level=info msg="Kube API server is now running"
2021-04-29T12:20:24.986781829Z  time="2021-04-29T12:20:24.986596119Z" level=info msg="k3s is up and running"
2021-04-29T12:20:24.986790908Z  Flag --address has been deprecated, see --bind-address instead.
2021-04-29T12:20:24.991795847Z  I0429 12:20:24.991594       7 controllermanager.go:176] Version: v1.20.6+k3s1
2021-04-29T12:20:24.992365617Z  I0429 12:20:24.992168       7 deprecated_insecure_serving.go:53] Serving insecurely on 127.0.0.1:10252
2021-04-29T12:20:24.999304686Z  time="2021-04-29T12:20:24.999098653Z" level=info msg="Creating CRD addons.k3s.cattle.io"
2021-04-29T12:20:25.008876026Z  W0429 12:20:25.008729       7 authorization.go:47] Authorization is disabled
2021-04-29T12:20:25.008955646Z  W0429 12:20:25.008756       7 authentication.go:40] Authentication is disabled
2021-04-29T12:20:25.008975342Z  I0429 12:20:25.008777       7 deprecated_insecure_serving.go:51] Serving healthz insecurely on 127.0.0.1:10251
2021-04-29T12:20:25.009943071Z  time="2021-04-29T12:20:25.009752682Z" level=info msg="Creating CRD helmcharts.helm.cattle.io"
2021-04-29T12:20:25.015680371Z  time="2021-04-29T12:20:25.015525741Z" level=info msg="Creating CRD helmchartconfigs.helm.cattle.io"
2021-04-29T12:20:25.026847319Z  time="2021-04-29T12:20:25.026667406Z" level=info msg="Waiting for CRD helmcharts.helm.cattle.io to become available"
2021-04-29T12:20:25.532952696Z  time="2021-04-29T12:20:25.532550966Z" level=info msg="Done waiting for CRD helmcharts.helm.cattle.io to become available"
2021-04-29T12:20:25.532989852Z  time="2021-04-29T12:20:25.532826003Z" level=info msg="Waiting for CRD helmchartconfigs.helm.cattle.io to become available"
2021-04-29T12:20:26.035511363Z  time="2021-04-29T12:20:26.035042654Z" level=info msg="Done waiting for CRD helmchartconfigs.helm.cattle.io to become available"
2021-04-29T12:20:26.040413844Z  time="2021-04-29T12:20:26.040289316Z" level=info msg="Writing static file: /var/lib/rancher/k3s/server/static/charts/traefik-1.81.0.tgz"
2021-04-29T12:20:26.040772901Z  time="2021-04-29T12:20:26.040676589Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/local-storage.yaml"
2021-04-29T12:20:26.040857759Z  time="2021-04-29T12:20:26.040780444Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/auth-delegator.yaml"
2021-04-29T12:20:26.041034040Z  time="2021-04-29T12:20:26.040942128Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/auth-reader.yaml"
2021-04-29T12:20:26.041153539Z  time="2021-04-29T12:20:26.041057367Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-apiservice.yaml"
2021-04-29T12:20:26.041368233Z  time="2021-04-29T12:20:26.041280861Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-deployment.yaml"
2021-04-29T12:20:26.041437446Z  time="2021-04-29T12:20:26.041368233Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/resource-reader.yaml"
2021-04-29T12:20:26.041562184Z  time="2021-04-29T12:20:26.041503726Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/traefik.yaml"
2021-04-29T12:20:26.041628743Z  time="2021-04-29T12:20:26.041599200Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/ccm.yaml"
2021-04-29T12:20:26.041735951Z  time="2021-04-29T12:20:26.041706407Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/coredns.yaml"
2021-04-29T12:20:26.041806491Z  time="2021-04-29T12:20:26.041777437Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/aggregated-metrics-reader.yaml"
2021-04-29T12:20:26.041877450Z  time="2021-04-29T12:20:26.041846929Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-service.yaml"
2021-04-29T12:20:26.041956162Z  time="2021-04-29T12:20:26.041928574Z" level=info msg="Writing manifest: /var/lib/rancher/k3s/server/manifests/rolebindings.yaml"
2021-04-29T12:20:26.143204392Z  time="2021-04-29T12:20:26.142976568Z" level=info msg="Starting k3s.cattle.io/v1, Kind=Addon controller"
2021-04-29T12:20:26.147668685Z  time="2021-04-29T12:20:26.147490378Z" level=info msg="Waiting for control-plane node k3d-default-server-0 startup: nodes \"k3d-default-server-0\" not found"
2021-04-29T12:20:26.152335449Z  time="2021-04-29T12:20:26.152206241Z" level=info msg="Cluster dns configmap has been set successfully"
2021-04-29T12:20:26.166973468Z  I0429 12:20:26.166854       7 controller.go:609] quota admission added evaluator for: addons.k3s.cattle.io
2021-04-29T12:20:26.203340062Z  I0429 12:20:26.203043       7 controller.go:609] quota admission added evaluator for: serviceaccounts
2021-04-29T12:20:26.219034929Z  E0429 12:20:26.218923       7 node.go:161] Failed to retrieve node info: nodes "k3d-default-server-0" not found
2021-04-29T12:20:26.245051586Z  time="2021-04-29T12:20:26.244954715Z" level=info msg="Starting /v1, Kind=Pod controller"
2021-04-29T12:20:26.245077707Z  time="2021-04-29T12:20:26.244956182Z" level=info msg="Starting /v1, Kind=Endpoints controller"
2021-04-29T12:20:26.245150831Z  time="2021-04-29T12:20:26.244956182Z" level=info msg="Starting /v1, Kind=Service controller"
2021-04-29T12:20:26.245175066Z  time="2021-04-29T12:20:26.244971826Z" level=info msg="Starting helm.cattle.io/v1, Kind=HelmChart controller"
2021-04-29T12:20:26.245196508Z  time="2021-04-29T12:20:26.244974201Z" level=info msg="Starting /v1, Kind=Node controller"
2021-04-29T12:20:26.245236108Z  time="2021-04-29T12:20:26.244977065Z" level=info msg="Starting batch/v1, Kind=Job controller"
2021-04-29T12:20:26.245252381Z  time="2021-04-29T12:20:26.244979439Z" level=info msg="Starting helm.cattle.io/v1, Kind=HelmChartConfig controller"
2021-04-29T12:20:26.245880469Z  I0429 12:20:26.245801       7 controller.go:609] quota admission added evaluator for: deployments.apps
2021-04-29T12:20:26.503505077Z  I0429 12:20:26.503279       7 controller.go:609] quota admission added evaluator for: helmcharts.helm.cattle.io
2021-04-29T12:20:26.534800662Z  I0429 12:20:26.534488       7 controller.go:609] quota admission added evaluator for: jobs.batch
2021-04-29T12:20:26.665234834Z  I0429 12:20:26.665043       7 request.go:655] Throttling request took 1.048468955s, request: GET:https://127.0.0.1:6444/apis/authentication.k8s.io/v1beta1?timeout=32s
2021-04-29T12:20:26.715771577Z  time="2021-04-29T12:20:26.715320957Z" level=info msg="Waiting for node k3d-default-server-0: nodes \"k3d-default-server-0\" not found"
2021-04-29T12:20:27.037271818Z  time="2021-04-29T12:20:27.037004184Z" level=info msg="Starting /v1, Kind=Secret controller"
2021-04-29T12:20:27.147610317Z  time="2021-04-29T12:20:27.147401280Z" level=info msg="Active TLS secret k3s-serving (ver=268) (count 8): map[listener.cattle.io/cn-0.0.0.0:0.0.0.0 listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.27.0.2:172.27.0.2 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=FEA5BA991F79AE1DDF81C48B70DD34E159778B6F]"
2021-04-29T12:20:27.347258765Z  time="2021-04-29T12:20:27.347136751Z" level=info msg="Waiting for control-plane node k3d-default-server-0 startup: nodes \"k3d-default-server-0\" not found"
2021-04-29T12:20:27.569923184Z  I0429 12:20:27.569671       7 shared_informer.go:240] Waiting for caches to sync for tokens
2021-04-29T12:20:27.592190450Z  I0429 12:20:27.591931       7 controllermanager.go:554] Started "endpointslice"
2021-04-29T12:20:27.592238711Z  I0429 12:20:27.592036       7 endpointslice_controller.go:237] Starting endpoint slice controller
2021-04-29T12:20:27.592250095Z  I0429 12:20:27.592055       7 shared_informer.go:240] Waiting for caches to sync for endpoint_slice
2021-04-29T12:20:27.605236982Z  I0429 12:20:27.605008       7 controllermanager.go:554] Started "csrapproving"
2021-04-29T12:20:27.605347332Z  I0429 12:20:27.605120       7 certificate_controller.go:118] Starting certificate controller "csrapproving"
2021-04-29T12:20:27.605377294Z  I0429 12:20:27.605200       7 shared_informer.go:240] Waiting for caches to sync for certificate-csrapproving
2021-04-29T12:20:27.622075928Z  I0429 12:20:27.621799       7 controllermanager.go:554] Started "disruption"
2021-04-29T12:20:27.622141649Z  W0429 12:20:27.621826       7 controllermanager.go:533] "service" is disabled
2021-04-29T12:20:27.622152126Z  I0429 12:20:27.621889       7 disruption.go:331] Starting disruption controller
2021-04-29T12:20:27.622161135Z  I0429 12:20:27.621910       7 shared_informer.go:240] Waiting for caches to sync for disruption
2021-04-29T12:20:27.634228694Z  I0429 12:20:27.634005       7 controllermanager.go:554] Started "pv-protection"
2021-04-29T12:20:27.634281354Z  I0429 12:20:27.634087       7 pv_protection_controller.go:83] Starting PV protection controller
2021-04-29T12:20:27.634293507Z  I0429 12:20:27.634136       7 shared_informer.go:240] Waiting for caches to sync for PV protection
2021-04-29T12:20:27.639563286Z  I0429 12:20:27.639325       7 certificate_controller.go:118] Starting certificate controller "csrsigning-kubelet-serving"
2021-04-29T12:20:27.639608823Z  I0429 12:20:27.639376       7 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kubelet-serving
2021-04-29T12:20:27.639619788Z  I0429 12:20:27.639422       7 dynamic_serving_content.go:130] Starting csr-controller::/var/lib/rancher/k3s/server/tls/client-ca.crt::/var/lib/rancher/k3s/server/tls/client-ca.key
2021-04-29T12:20:27.639970394Z  I0429 12:20:27.639833       7 certificate_controller.go:118] Starting certificate controller "csrsigning-kubelet-client"
2021-04-29T12:20:27.640030947Z  I0429 12:20:27.639868       7 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kubelet-client
2021-04-29T12:20:27.640045823Z  I0429 12:20:27.639917       7 dynamic_serving_content.go:130] Starting csr-controller::/var/lib/rancher/k3s/server/tls/client-ca.crt::/var/lib/rancher/k3s/server/tls/client-ca.key
2021-04-29T12:20:27.640614057Z  I0429 12:20:27.640471       7 certificate_controller.go:118] Starting certificate controller "csrsigning-kube-apiserver-client"
2021-04-29T12:20:27.640683061Z  I0429 12:20:27.640507       7 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kube-apiserver-client
2021-04-29T12:20:27.640695353Z  I0429 12:20:27.640542       7 dynamic_serving_content.go:130] Starting csr-controller::/var/lib/rancher/k3s/server/tls/client-ca.crt::/var/lib/rancher/k3s/server/tls/client-ca.key
2021-04-29T12:20:27.641124741Z  I0429 12:20:27.640979       7 controllermanager.go:554] Started "csrsigning"
2021-04-29T12:20:27.641208691Z  I0429 12:20:27.641015       7 certificate_controller.go:118] Starting certificate controller "csrsigning-legacy-unknown"
2021-04-29T12:20:27.641223008Z  I0429 12:20:27.641036       7 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-legacy-unknown
2021-04-29T12:20:27.641232577Z  I0429 12:20:27.641066       7 dynamic_serving_content.go:130] Starting csr-controller::/var/lib/rancher/k3s/server/tls/client-ca.crt::/var/lib/rancher/k3s/server/tls/client-ca.key
2021-04-29T12:20:27.653328980Z  I0429 12:20:27.653133       7 node_lifecycle_controller.go:380] Sending events to api server.
2021-04-29T12:20:27.653494296Z  I0429 12:20:27.653357       7 taint_manager.go:163] Sending events to api server.
2021-04-29T12:20:27.653714298Z  I0429 12:20:27.653545       7 node_lifecycle_controller.go:508] Controller will reconcile labels.
2021-04-29T12:20:27.653761930Z  I0429 12:20:27.653660       7 controllermanager.go:554] Started "nodelifecycle"
2021-04-29T12:20:27.653773523Z  W0429 12:20:27.653689       7 controllermanager.go:533] "route" is disabled
2021-04-29T12:20:27.653816686Z  I0429 12:20:27.653732       7 node_lifecycle_controller.go:542] Starting node controller
2021-04-29T12:20:27.653909925Z  I0429 12:20:27.653757       7 shared_informer.go:240] Waiting for caches to sync for taint
2021-04-29T12:20:27.666549628Z  I0429 12:20:27.666347       7 controllermanager.go:554] Started "pvc-protection"
2021-04-29T12:20:27.666627292Z  I0429 12:20:27.666455       7 pvc_protection_controller.go:110] Starting PVC protection controller
2021-04-29T12:20:27.666676391Z  I0429 12:20:27.666539       7 shared_informer.go:240] Waiting for caches to sync for PVC protection
2021-04-29T12:20:27.669975721Z  I0429 12:20:27.669801       7 shared_informer.go:247] Caches are synced for tokens 
2021-04-29T12:20:27.682682612Z  I0429 12:20:27.682484       7 controllermanager.go:554] Started "endpointslicemirroring"
2021-04-29T12:20:27.682743235Z  I0429 12:20:27.682620       7 endpointslicemirroring_controller.go:211] Starting EndpointSliceMirroring controller
2021-04-29T12:20:27.682756086Z  I0429 12:20:27.682645       7 shared_informer.go:240] Waiting for caches to sync for endpoint_slice_mirroring
2021-04-29T12:20:27.686434797Z  time="2021-04-29T12:20:27.686152007Z" level=info msg="Stopped tunnel to 127.0.0.1:6443"
2021-04-29T12:20:27.686494861Z  time="2021-04-29T12:20:27.686179106Z" level=info msg="Connecting to proxy" url="wss://172.27.0.2:6443/v1-k3s/connect"
2021-04-29T12:20:27.686618481Z  time="2021-04-29T12:20:27.686200058Z" level=info msg="Proxy done" err="context canceled" url="wss://127.0.0.1:6443/v1-k3s/connect"
2021-04-29T12:20:27.686778698Z  time="2021-04-29T12:20:27.686614710Z" level=info msg="error in remotedialer server [400]: websocket: close 1006 (abnormal closure): unexpected EOF"
2021-04-29T12:20:27.690417460Z  time="2021-04-29T12:20:27.690245998Z" level=info msg="Handling backend connection request [k3d-default-server-0]"
2021-04-29T12:20:27.698337599Z  I0429 12:20:27.698165       7 controllermanager.go:554] Started "podgc"
2021-04-29T12:20:27.698382996Z  I0429 12:20:27.698213       7 gc_controller.go:89] Starting GC controller
2021-04-29T12:20:27.698393821Z  I0429 12:20:27.698235       7 shared_informer.go:240] Waiting for caches to sync for GC
2021-04-29T12:20:27.712642751Z  I0429 12:20:27.712495       7 controllermanager.go:554] Started "deployment"
2021-04-29T12:20:27.712716993Z  I0429 12:20:27.712640       7 deployment_controller.go:153] Starting deployment controller
2021-04-29T12:20:27.712732009Z  I0429 12:20:27.712668       7 shared_informer.go:240] Waiting for caches to sync for deployment
2021-04-29T12:20:27.725192358Z  I0429 12:20:27.724957       7 controllermanager.go:554] Started "daemonset"
2021-04-29T12:20:27.725243273Z  I0429 12:20:27.725046       7 daemon_controller.go:285] Starting daemon sets controller
2021-04-29T12:20:27.725258219Z  I0429 12:20:27.725070       7 shared_informer.go:240] Waiting for caches to sync for daemon sets
2021-04-29T12:20:27.741216808Z  W0429 12:20:27.740979       7 info.go:53] Couldn't collect info from any of the files in "/etc/machine-id,/var/lib/dbus/machine-id"
2021-04-29T12:20:27.741839728Z  I0429 12:20:27.741675       7 server.go:645] --cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /
2021-04-29T12:20:27.742197109Z  I0429 12:20:27.742017       7 container_manager_linux.go:287] container manager verified user specified cgroup-root exists: []
2021-04-29T12:20:27.742280081Z  I0429 12:20:27.742045       7 container_manager_linux.go:292] Creating Container Manager object based on Node Config: {RuntimeCgroupsName:/k3s SystemCgroupsName: KubeletCgroupsName:/k3s ContainerRuntime:remote CgroupsPerQOS:true CgroupRoot:/ CgroupDriver:cgroupfs KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[{Signal:imagefs.available Operator:LessThan Value:{Quantity:<nil> Percentage:0.05} GracePeriod:0s MinReclaim:<nil>} {Signal:nodefs.available Operator:LessThan Value:{Quantity:<nil> Percentage:0.05} GracePeriod:0s MinReclaim:<nil>}]} QOSReserved:map[] ExperimentalCPUManagerPolicy:none ExperimentalTopologyManagerScope:container ExperimentalCPUManagerReconcilePeriod:10s ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none Rootless:false}
2021-04-29T12:20:27.742332672Z  I0429 12:20:27.742182       7 topology_manager.go:120] [topologymanager] Creating topology manager with none policy per container scope
2021-04-29T12:20:27.742343218Z  I0429 12:20:27.742199       7 container_manager_linux.go:323] [topologymanager] Initializing Topology Manager with none policy and container-level scope
2021-04-29T12:20:27.742352298Z  I0429 12:20:27.742211       7 container_manager_linux.go:328] Creating device plugin manager: true
2021-04-29T12:20:27.742814092Z  I0429 12:20:27.742642       7 kubelet.go:265] Adding pod path: /var/lib/rancher/k3s/agent/pod-manifests
2021-04-29T12:20:27.742873248Z  I0429 12:20:27.742682       7 kubelet.go:276] Watching apiserver
2021-04-29T12:20:27.742895248Z  I0429 12:20:27.742770       7 kubelet.go:453] Kubelet client is not nil
2021-04-29T12:20:27.744618457Z  I0429 12:20:27.744472       7 kuberuntime_manager.go:216] Container runtime containerd initialized, version: v1.4.4-k3s1, apiVersion: v1alpha2
2021-04-29T12:20:27.744963266Z  W0429 12:20:27.744831       7 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
2021-04-29T12:20:27.745755972Z  I0429 12:20:27.745678       7 server.go:1177] Started kubelet
2021-04-29T12:20:27.746078431Z  I0429 12:20:27.745867       7 server.go:148] Starting to listen on 0.0.0.0:10250
2021-04-29T12:20:27.746858845Z  E0429 12:20:27.746709       7 cri_stats_provider.go:376] Failed to get the info of the filesystem with mountpoint "/var/lib/rancher/k3s/agent/containerd/io.containerd.snapshotter.v1.overlayfs": unable to find data in memory cache.
2021-04-29T12:20:27.746916953Z  E0429 12:20:27.746836       7 kubelet.go:1296] Image garbage collection failed once. Stats initialization may not have completed yet: invalid capacity 0 on image filesystem
2021-04-29T12:20:27.747451453Z  I0429 12:20:27.747326       7 fs_resource_analyzer.go:64] Starting FS ResourceAnalyzer
2021-04-29T12:20:27.747637581Z  I0429 12:20:27.747537       7 volume_manager.go:271] Starting Kubelet Volume Manager
2021-04-29T12:20:27.747674318Z  I0429 12:20:27.747586       7 desired_state_of_world_populator.go:142] Desired state populator starts to run
2021-04-29T12:20:27.748046436Z  I0429 12:20:27.747952       7 server.go:410] Adding debug handlers to kubelet server.
2021-04-29T12:20:27.757292452Z  I0429 12:20:27.757160       7 cpu_manager.go:193] [cpumanager] starting with none policy
2021-04-29T12:20:27.757334427Z  I0429 12:20:27.757182       7 cpu_manager.go:194] [cpumanager] reconciling every 10s
2021-04-29T12:20:27.757348675Z  I0429 12:20:27.757214       7 state_mem.go:36] [cpumanager] initializing new in-memory state store
2021-04-29T12:20:27.759886799Z  E0429 12:20:27.759778       7 nodelease.go:49] failed to get node "k3d-default-server-0" when trying to set owner ref to the node lease: nodes "k3d-default-server-0" not found
2021-04-29T12:20:27.767460801Z  I0429 12:20:27.767326       7 policy_none.go:43] [cpumanager] none policy: Start
2021-04-29T12:20:27.778866747Z  I0429 12:20:27.778767       7 kubelet_network_linux.go:56] Initialized IPv4 iptables rules.
2021-04-29T12:20:27.778894964Z  I0429 12:20:27.778807       7 status_manager.go:158] Starting to sync pod status with apiserver
2021-04-29T12:20:27.778902925Z  I0429 12:20:27.778830       7 kubelet.go:1833] Starting kubelet main sync loop.
2021-04-29T12:20:27.778951745Z  E0429 12:20:27.778897       7 kubelet.go:1857] skipping pod synchronization - [container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]
2021-04-29T12:20:27.787993474Z  W0429 12:20:27.787836       7 manager.go:594] Failed to retrieve checkpoint for "kubelet_internal_checkpoint": checkpoint is not found
2021-04-29T12:20:27.788135253Z  I0429 12:20:27.788060       7 plugin_manager.go:114] Starting Kubelet Plugin Manager
2021-04-29T12:20:27.788516590Z  E0429 12:20:27.788398       7 eviction_manager.go:260] eviction manager: failed to get summary stats: failed to get node info: node "k3d-default-server-0" not found
2021-04-29T12:20:27.824323751Z  I0429 12:20:27.824076       7 controllermanager.go:554] Started "job"
2021-04-29T12:20:27.824371942Z  W0429 12:20:27.824127       7 controllermanager.go:533] "cloud-node-lifecycle" is disabled
2021-04-29T12:20:27.824383675Z  I0429 12:20:27.824131       7 job_controller.go:148] Starting job controller
2021-04-29T12:20:27.824393313Z  I0429 12:20:27.824183       7 shared_informer.go:240] Waiting for caches to sync for job
2021-04-29T12:20:27.848237120Z  E0429 12:20:27.847971       7 kubelet.go:2268] node "k3d-default-server-0" not found
2021-04-29T12:20:27.849722727Z  I0429 12:20:27.849585       7 kubelet_node_status.go:71] Attempting to register node k3d-default-server-0
2021-04-29T12:20:27.948357264Z  I0429 12:20:27.948122       7 reconciler.go:157] Reconciler: start to sync state
2021-04-29T12:20:27.948402172Z  E0429 12:20:27.948202       7 kubelet.go:2268] node "k3d-default-server-0" not found
2021-04-29T12:20:27.981886183Z  I0429 12:20:27.981691       7 controllermanager.go:554] Started "persistentvolume-binder"
2021-04-29T12:20:27.981939682Z  W0429 12:20:27.981739       7 controllermanager.go:546] Skipping "ttl-after-finished"
2021-04-29T12:20:27.981959727Z  I0429 12:20:27.981856       7 pv_controller_base.go:307] Starting persistent volume controller
2021-04-29T12:20:27.981971181Z  I0429 12:20:27.981874       7 shared_informer.go:240] Waiting for caches to sync for persistent volume
2021-04-29T12:20:28.001654856Z  time="2021-04-29T12:20:28.001531376Z" level=info msg="Running cloud-controller-manager with args --profiling=false"
2021-04-29T12:20:28.004463757Z  I0429 12:20:28.004355       7 controllermanager.go:141] Version: v1.20.6+k3s1
2021-04-29T12:20:28.047397443Z  W0429 12:20:28.047200       7 handler_proxy.go:102] no RequestInfo found in the context
2021-04-29T12:20:28.047453596Z  E0429 12:20:28.047342       7 controller.go:116] loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
2021-04-29T12:20:28.047459742Z  , Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2021-04-29T12:20:28.047464003Z  I0429 12:20:28.047397       7 controller.go:129] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
2021-04-29T12:20:28.049430750Z  E0429 12:20:28.049218       7 kubelet.go:2268] node "k3d-default-server-0" not found
2021-04-29T12:20:28.149477979Z  E0429 12:20:28.149306       7 kubelet.go:2268] node "k3d-default-server-0" not found
2021-04-29T12:20:28.149856452Z  I0429 12:20:28.149731       7 kubelet_node_status.go:74] Successfully registered node k3d-default-server-0
2021-04-29T12:20:28.158455384Z  time="2021-04-29T12:20:28.158271700Z" level=info msg="Updated coredns node hosts entry [172.27.0.2 k3d-default-server-0]"
2021-04-29T12:20:28.353320920Z  time="2021-04-29T12:20:28.353227961Z" level=info msg="Control-plane role label has been set successfully on node: k3d-default-server-0"
2021-04-29T12:20:28.720690581Z  time="2021-04-29T12:20:28.720524916Z" level=info msg="Waiting for node k3d-default-server-0 CIDR not assigned yet"
2021-04-29T12:20:28.786166501Z  E0429 12:20:28.785983       7 resource_quota_controller.go:162] initial discovery check failure, continuing and counting on future sync update: unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
2021-04-29T12:20:28.786214063Z  I0429 12:20:28.786093       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for roles.rbac.authorization.k8s.io
2021-04-29T12:20:28.786304159Z  I0429 12:20:28.786176       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for limitranges
2021-04-29T12:20:28.786350534Z  W0429 12:20:28.786217       7 shared_informer.go:494] resyncPeriod 20h31m38.691428153s is smaller than resyncCheckPeriod 21h49m29.304037554s and the informer has already started. Changing it to 21h49m29.304037554s
2021-04-29T12:20:28.786466262Z  I0429 12:20:28.786336       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for serviceaccounts
2021-04-29T12:20:28.786501043Z  I0429 12:20:28.786372       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for daemonsets.apps
2021-04-29T12:20:28.786518294Z  I0429 12:20:28.786418       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for rolebindings.rbac.authorization.k8s.io
2021-04-29T12:20:28.786529259Z  I0429 12:20:28.786470       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for replicasets.apps
2021-04-29T12:20:28.786540155Z  I0429 12:20:28.786511       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for jobs.batch
2021-04-29T12:20:28.786607482Z  W0429 12:20:28.786545       7 shared_informer.go:494] resyncPeriod 14h53m53.241941131s is smaller than resyncCheckPeriod 21h49m29.304037554s and the informer has already started. Changing it to 21h49m29.304037554s
2021-04-29T12:20:28.786750588Z  I0429 12:20:28.786647       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for deployments.apps
2021-04-29T12:20:28.786782017Z  I0429 12:20:28.786709       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for helmchartconfigs.helm.cattle.io
2021-04-29T12:20:28.786824970Z  I0429 12:20:28.786757       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for events.events.k8s.io
2021-04-29T12:20:28.786863173Z  I0429 12:20:28.786794       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for cronjobs.batch
2021-04-29T12:20:28.786934063Z  I0429 12:20:28.786824       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for statefulsets.apps
2021-04-29T12:20:28.786964933Z  I0429 12:20:28.786859       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for poddisruptionbudgets.policy
2021-04-29T12:20:28.787062153Z  I0429 12:20:28.786895       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for helmcharts.helm.cattle.io
2021-04-29T12:20:28.787083525Z  I0429 12:20:28.786958       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for addons.k3s.cattle.io
2021-04-29T12:20:28.787095048Z  I0429 12:20:28.787010       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for endpoints
2021-04-29T12:20:28.787129830Z  I0429 12:20:28.787068       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for controllerrevisions.apps
2021-04-29T12:20:28.787163703Z  I0429 12:20:28.787099       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for leases.coordination.k8s.io
2021-04-29T12:20:28.787215246Z  I0429 12:20:28.787163       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for networkpolicies.networking.k8s.io
2021-04-29T12:20:28.787329298Z  I0429 12:20:28.787205       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for podtemplates
2021-04-29T12:20:28.787354581Z  I0429 12:20:28.787254       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for horizontalpodautoscalers.autoscaling
2021-04-29T12:20:28.787365965Z  I0429 12:20:28.787296       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for ingresses.networking.k8s.io
2021-04-29T12:20:28.787411851Z  I0429 12:20:28.787338       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for ingresses.extensions
2021-04-29T12:20:28.787491750Z  I0429 12:20:28.787430       7 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for endpointslices.discovery.k8s.io
2021-04-29T12:20:28.787511795Z  I0429 12:20:28.787473       7 controllermanager.go:554] Started "resourcequota"
2021-04-29T12:20:28.787629548Z  I0429 12:20:28.787513       7 resource_quota_controller.go:273] Starting resource quota controller
2021-04-29T12:20:28.787660069Z  I0429 12:20:28.787543       7 shared_informer.go:240] Waiting for caches to sync for resource quota
2021-04-29T12:20:28.787669707Z  I0429 12:20:28.787587       7 resource_quota_monitor.go:304] QuotaMonitor running
2021-04-29T12:20:28.800658341Z  I0429 12:20:28.800518       7 controllermanager.go:554] Started "serviceaccount"
2021-04-29T12:20:28.800711001Z  I0429 12:20:28.800649       7 serviceaccounts_controller.go:117] Starting service account controller
2021-04-29T12:20:28.800726367Z  I0429 12:20:28.800664       7 shared_informer.go:240] Waiting for caches to sync for service account
2021-04-29T12:20:28.812513510Z  I0429 12:20:28.812387       7 garbagecollector.go:142] Starting garbage collector controller
2021-04-29T12:20:28.812537745Z  I0429 12:20:28.812410       7 shared_informer.go:240] Waiting for caches to sync for garbage collector
2021-04-29T12:20:28.812542425Z  I0429 12:20:28.812443       7 graph_builder.go:289] GraphBuilder running
2021-04-29T12:20:28.812743569Z  I0429 12:20:28.812549       7 controllermanager.go:554] Started "garbagecollector"
2021-04-29T12:20:28.973941481Z  I0429 12:20:28.973771       7 controllermanager.go:554] Started "horizontalpodautoscaling"
2021-04-29T12:20:28.974032555Z  I0429 12:20:28.973899       7 horizontal.go:169] Starting HPA controller
2021-04-29T12:20:28.974053856Z  I0429 12:20:28.973966       7 shared_informer.go:240] Waiting for caches to sync for HPA
2021-04-29T12:20:29.023722465Z  I0429 12:20:29.023583       7 node_ipam_controller.go:91] Sending events to api server.
2021-04-29T12:20:30.721156397Z  E0429 12:20:30.720952       7 controllermanager.go:391] unable to get all supported resources from server: unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
2021-04-29T12:20:30.723267018Z  I0429 12:20:30.723064       7 node_controller.go:115] Sending events to api server.
2021-04-29T12:20:30.723462156Z  I0429 12:20:30.723239       7 controllermanager.go:258] Started "cloud-node"
2021-04-29T12:20:30.723537376Z  I0429 12:20:30.723328       7 node_controller.go:154] Waiting for informer caches to sync
2021-04-29T12:20:30.725468574Z  I0429 12:20:30.725254       7 node_lifecycle_controller.go:77] Sending events to api server
2021-04-29T12:20:30.725516555Z  I0429 12:20:30.725313       7 controllermanager.go:258] Started "cloud-node-lifecycle"
2021-04-29T12:20:30.730483500Z  time="2021-04-29T12:20:30.730236329Z" level=info msg="Waiting for node k3d-default-server-0 CIDR not assigned yet"
2021-04-29T12:20:30.823948202Z  I0429 12:20:30.823698       7 node_controller.go:390] Initializing node k3d-default-server-0 with cloud provider
2021-04-29T12:20:30.823997860Z  time="2021-04-29T12:20:30.823779394Z" level=info msg="Couldn't find node internal ip label on node k3d-default-server-0"
2021-04-29T12:20:30.824009383Z  time="2021-04-29T12:20:30.823828982Z" level=info msg="Couldn't find node hostname label on node k3d-default-server-0"
2021-04-29T12:20:30.829120971Z  time="2021-04-29T12:20:30.828910956Z" level=info msg="Couldn't find node internal ip label on node k3d-default-server-0"
2021-04-29T12:20:30.829196260Z  time="2021-04-29T12:20:30.828956772Z" level=info msg="Couldn't find node hostname label on node k3d-default-server-0"
2021-04-29T12:20:30.835803790Z  I0429 12:20:30.835580       7 node_controller.go:454] Successfully initialized node k3d-default-server-0 with cloud provider
2021-04-29T12:20:30.835860153Z  I0429 12:20:30.835667       7 event.go:291] "Event occurred" object="k3d-default-server-0" kind="Node" apiVersion="v1" type="Normal" reason="Synced" message="Node synced successfully"
2021-04-29T12:20:30.884840469Z  E0429 12:20:30.884631       7 resource_quota_controller.go:409] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
2021-04-29T12:20:30.962278347Z  I0429 12:20:30.962044       7 node.go:172] Successfully retrieved node IP: 172.27.0.2
2021-04-29T12:20:30.962331217Z  I0429 12:20:30.962093       7 server_others.go:143] kube-proxy node IP is an IPv4 address (172.27.0.2), assume IPv4 operation
2021-04-29T12:20:30.963549888Z  I0429 12:20:30.963320       7 server_others.go:186] Using iptables Proxier.
2021-04-29T12:20:30.963939955Z  I0429 12:20:30.963707       7 server.go:650] Version: v1.20.6+k3s1
2021-04-29T12:20:30.964508119Z  I0429 12:20:30.964397       7 conntrack.go:52] Setting nf_conntrack_max to 524288
2021-04-29T12:20:30.964842592Z  I0429 12:20:30.964742       7 conntrack.go:83] Setting conntrack hashsize to 131072
2021-04-29T12:20:30.964893576Z  E0429 12:20:30.964772       7 conntrack.go:85] failed to set conntrack hashsize to 131072: write /sys/module/nf_conntrack/parameters/hashsize: operation not supported
2021-04-29T12:20:30.964917322Z  I0429 12:20:30.964817       7 conntrack.go:103] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_established' to 86400
2021-04-29T12:20:30.964929894Z  I0429 12:20:30.964856       7 conntrack.go:103] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_close_wait' to 3600
2021-04-29T12:20:30.965193966Z  I0429 12:20:30.965007       7 config.go:315] Starting service config controller
2021-04-29T12:20:30.965232239Z  I0429 12:20:30.965022       7 shared_informer.go:240] Waiting for caches to sync for service config
2021-04-29T12:20:30.965289440Z  I0429 12:20:30.965078       7 config.go:224] Starting endpoint slice config controller
2021-04-29T12:20:30.965309834Z  I0429 12:20:30.965127       7 shared_informer.go:240] Waiting for caches to sync for endpoint slice config
2021-04-29T12:20:31.065622183Z  I0429 12:20:31.065414       7 shared_informer.go:247] Caches are synced for endpoint slice config 
2021-04-29T12:20:31.065668488Z  I0429 12:20:31.065417       7 shared_informer.go:247] Caches are synced for service config 
2021-04-29T12:20:31.512551656Z  W0429 12:20:31.512286       7 garbagecollector.go:703] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
2021-04-29T12:20:32.743832418Z  time="2021-04-29T12:20:32.743631902Z" level=info msg="Waiting for node k3d-default-server-0 CIDR not assigned yet"
2021-04-29T12:20:34.758186640Z  time="2021-04-29T12:20:34.757913907Z" level=info msg="Waiting for node k3d-default-server-0 CIDR not assigned yet"
2021-04-29T12:20:36.774120895Z  time="2021-04-29T12:20:36.773855007Z" level=info msg="Waiting for node k3d-default-server-0 CIDR not assigned yet"
2021-04-29T12:20:37.776372547Z  I0429 12:20:37.776131       7 controller.go:609] quota admission added evaluator for: leases.coordination.k8s.io
2021-04-29T12:20:38.782220288Z  time="2021-04-29T12:20:38.781953492Z" level=info msg="Waiting for node k3d-default-server-0 CIDR not assigned yet"
2021-04-29T12:20:39.062325249Z  I0429 12:20:39.062141       7 range_allocator.go:82] Sending events to api server.
2021-04-29T12:20:39.062637582Z  I0429 12:20:39.062440       7 range_allocator.go:110] No Service CIDR provided. Skipping filtering out service addresses.
2021-04-29T12:20:39.062685563Z  I0429 12:20:39.062467       7 range_allocator.go:116] No Secondary Service CIDR provided. Skipping filtering out secondary service addresses.
2021-04-29T12:20:39.062696948Z  I0429 12:20:39.062514       7 controllermanager.go:554] Started "nodeipam"
2021-04-29T12:20:39.062774053Z  I0429 12:20:39.062637       7 node_ipam_controller.go:159] Starting ipam controller
2021-04-29T12:20:39.062814002Z  I0429 12:20:39.062660       7 shared_informer.go:240] Waiting for caches to sync for node
2021-04-29T12:20:39.077019211Z  I0429 12:20:39.076821       7 controllermanager.go:554] Started "attachdetach"
2021-04-29T12:20:39.077066075Z  I0429 12:20:39.076911       7 attach_detach_controller.go:328] Starting attach detach controller
2021-04-29T12:20:39.077076971Z  I0429 12:20:39.076931       7 shared_informer.go:240] Waiting for caches to sync for attach detach
2021-04-29T12:20:39.090665126Z  I0429 12:20:39.090432       7 controllermanager.go:554] Started "endpoint"
2021-04-29T12:20:39.090718276Z  I0429 12:20:39.090622       7 endpoints_controller.go:184] Starting endpoint controller
2021-04-29T12:20:39.090731197Z  I0429 12:20:39.090646       7 shared_informer.go:240] Waiting for caches to sync for endpoint
2021-04-29T12:20:39.104140418Z  I0429 12:20:39.103905       7 controllermanager.go:554] Started "replicationcontroller"
2021-04-29T12:20:39.104282197Z  I0429 12:20:39.104032       7 replica_set.go:182] Starting replicationcontroller controller
2021-04-29T12:20:39.104301892Z  I0429 12:20:39.104055       7 shared_informer.go:240] Waiting for caches to sync for ReplicationController
2021-04-29T12:20:39.151943410Z  E0429 12:20:39.151757       7 namespaced_resources_deleter.go:161] unable to get all supported resources from server: unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
2021-04-29T12:20:39.152054528Z  I0429 12:20:39.151905       7 controllermanager.go:554] Started "namespace"
2021-04-29T12:20:39.152140015Z  I0429 12:20:39.152013       7 namespace_controller.go:200] Starting namespace controller
2021-04-29T12:20:39.152192257Z  I0429 12:20:39.152030       7 shared_informer.go:240] Waiting for caches to sync for namespace
2021-04-29T12:20:39.165248776Z  I0429 12:20:39.164933       7 controllermanager.go:554] Started "clusterrole-aggregation"
2021-04-29T12:20:39.165308421Z  I0429 12:20:39.164996       7 clusterroleaggregation_controller.go:149] Starting ClusterRoleAggregator
2021-04-29T12:20:39.165326161Z  I0429 12:20:39.165017       7 shared_informer.go:240] Waiting for caches to sync for ClusterRoleAggregator
2021-04-29T12:20:39.169695608Z  I0429 12:20:39.169478       7 controllermanager.go:554] Started "csrcleaner"
2021-04-29T12:20:39.169775926Z  I0429 12:20:39.169663       7 cleaner.go:82] Starting CSR cleaner controller
2021-04-29T12:20:39.181690950Z  I0429 12:20:39.181466       7 controllermanager.go:554] Started "ttl"
2021-04-29T12:20:39.181801999Z  W0429 12:20:39.181504       7 controllermanager.go:533] "bootstrapsigner" is disabled
2021-04-29T12:20:39.181823440Z  I0429 12:20:39.181606       7 ttl_controller.go:121] Starting TTL controller
2021-04-29T12:20:39.181833009Z  I0429 12:20:39.181629       7 shared_informer.go:240] Waiting for caches to sync for TTL
2021-04-29T12:20:39.195660443Z  I0429 12:20:39.195473       7 controllermanager.go:554] Started "cronjob"
2021-04-29T12:20:39.195721904Z  I0429 12:20:39.195556       7 cronjob_controller.go:96] Starting CronJob Manager
2021-04-29T12:20:39.210124695Z  I0429 12:20:39.209971       7 controllermanager.go:554] Started "root-ca-cert-publisher"
2021-04-29T12:20:39.210236512Z  I0429 12:20:39.210012       7 publisher.go:98] Starting root CA certificate configmap publisher
2021-04-29T12:20:39.210255369Z  I0429 12:20:39.210036       7 shared_informer.go:240] Waiting for caches to sync for crt configmap
2021-04-29T12:20:39.228606462Z  I0429 12:20:39.228430       7 controllermanager.go:554] Started "persistentvolume-expander"
2021-04-29T12:20:39.228647040Z  W0429 12:20:39.228457       7 controllermanager.go:546] Skipping "ephemeral-volume"
2021-04-29T12:20:39.228657586Z  I0429 12:20:39.228513       7 expand_controller.go:310] Starting expand controller
2021-04-29T12:20:39.228667015Z  I0429 12:20:39.228524       7 shared_informer.go:240] Waiting for caches to sync for expand
2021-04-29T12:20:39.390620615Z  I0429 12:20:39.390439       7 controllermanager.go:554] Started "replicaset"
2021-04-29T12:20:39.390677886Z  I0429 12:20:39.390527       7 replica_set.go:182] Starting replicaset controller
2021-04-29T12:20:39.390687314Z  I0429 12:20:39.390538       7 shared_informer.go:240] Waiting for caches to sync for ReplicaSet
2021-04-29T12:20:39.530837259Z  I0429 12:20:39.530591       7 controllermanager.go:554] Started "statefulset"
2021-04-29T12:20:39.530882028Z  W0429 12:20:39.530627       7 controllermanager.go:533] "tokencleaner" is disabled
2021-04-29T12:20:39.530893063Z  I0429 12:20:39.530666       7 stateful_set.go:146] Starting stateful set controller
2021-04-29T12:20:39.530901653Z  I0429 12:20:39.530685       7 shared_informer.go:240] Waiting for caches to sync for stateful set
2021-04-29T12:20:39.531255123Z  I0429 12:20:39.531057       7 shared_informer.go:240] Waiting for caches to sync for resource quota
2021-04-29T12:20:39.539715489Z  W0429 12:20:39.539535       7 actual_state_of_world.go:534] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="k3d-default-server-0" does not exist
2021-04-29T12:20:39.548257429Z  E0429 12:20:39.548072       7 memcache.go:196] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
2021-04-29T12:20:39.552612559Z  I0429 12:20:39.552358       7 shared_informer.go:247] Caches are synced for namespace 
2021-04-29T12:20:39.554764806Z  I0429 12:20:39.554557       7 shared_informer.go:247] Caches are synced for taint 
2021-04-29T12:20:39.554818654Z  I0429 12:20:39.554648       7 node_lifecycle_controller.go:1429] Initializing eviction metric for zone: 
2021-04-29T12:20:39.554838280Z  W0429 12:20:39.554701       7 node_lifecycle_controller.go:1044] Missing timestamp for Node k3d-default-server-0. Assuming now as a timestamp.
2021-04-29T12:20:39.554852458Z  I0429 12:20:39.554730       7 taint_manager.go:187] Starting NoExecuteTaintManager
2021-04-29T12:20:39.554865029Z  I0429 12:20:39.554756       7 node_lifecycle_controller.go:1245] Controller detected that zone  is now in state Normal.
2021-04-29T12:20:39.555150753Z  I0429 12:20:39.554899       7 event.go:291] "Event occurred" object="k3d-default-server-0" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node k3d-default-server-0 event: Registered Node k3d-default-server-0 in Controller"
2021-04-29T12:20:39.562998744Z  I0429 12:20:39.562783       7 shared_informer.go:247] Caches are synced for node 
2021-04-29T12:20:39.563040580Z  I0429 12:20:39.562836       7 range_allocator.go:172] Starting range CIDR allocator
2021-04-29T12:20:39.563054478Z  I0429 12:20:39.562847       7 shared_informer.go:240] Waiting for caches to sync for cidrallocator
2021-04-29T12:20:39.563066840Z  I0429 12:20:39.562854       7 shared_informer.go:247] Caches are synced for cidrallocator 
2021-04-29T12:20:39.565777194Z  I0429 12:20:39.565562       7 shared_informer.go:247] Caches are synced for ClusterRoleAggregator 
2021-04-29T12:20:39.567419595Z  I0429 12:20:39.567178       7 shared_informer.go:247] Caches are synced for PVC protection 
2021-04-29T12:20:39.570511006Z  I0429 12:20:39.570309       7 range_allocator.go:373] Set node k3d-default-server-0 PodCIDR to [10.42.0.0/24]
2021-04-29T12:20:39.574909159Z  I0429 12:20:39.574620       7 shared_informer.go:247] Caches are synced for HPA 
2021-04-29T12:20:39.574973483Z  I0429 12:20:39.574775       7 kuberuntime_manager.go:1006] updating runtime config through cri with podcidr 10.42.0.0/24
2021-04-29T12:20:39.575982768Z  I0429 12:20:39.575812       7 kubelet_network.go:77] Setting Pod CIDR:  -> 10.42.0.0/24
2021-04-29T12:20:39.577215547Z  I0429 12:20:39.577012       7 shared_informer.go:247] Caches are synced for attach detach 
2021-04-29T12:20:39.581961652Z  I0429 12:20:39.581751       7 shared_informer.go:247] Caches are synced for TTL 
2021-04-29T12:20:39.582247445Z  I0429 12:20:39.582013       7 shared_informer.go:247] Caches are synced for persistent volume 
2021-04-29T12:20:39.592441146Z  I0429 12:20:39.592193       7 shared_informer.go:247] Caches are synced for endpoint_slice 
2021-04-29T12:20:39.598656514Z  I0429 12:20:39.598465       7 shared_informer.go:247] Caches are synced for GC 
2021-04-29T12:20:39.600968839Z  I0429 12:20:39.600741       7 shared_informer.go:247] Caches are synced for service account 
2021-04-29T12:20:39.604369090Z  I0429 12:20:39.604150       7 shared_informer.go:247] Caches are synced for ReplicationController 
2021-04-29T12:20:39.605691127Z  I0429 12:20:39.605502       7 shared_informer.go:247] Caches are synced for certificate-csrapproving 
2021-04-29T12:20:39.610514337Z  I0429 12:20:39.610309       7 shared_informer.go:247] Caches are synced for crt configmap 
2021-04-29T12:20:39.624563519Z  I0429 12:20:39.624325       7 shared_informer.go:247] Caches are synced for job 
2021-04-29T12:20:39.625502892Z  I0429 12:20:39.625259       7 shared_informer.go:247] Caches are synced for daemon sets 
2021-04-29T12:20:39.628962370Z  I0429 12:20:39.628719       7 shared_informer.go:247] Caches are synced for expand 
2021-04-29T12:20:39.634385801Z  I0429 12:20:39.634212       7 shared_informer.go:247] Caches are synced for PV protection 
2021-04-29T12:20:39.639597123Z  I0429 12:20:39.639434       7 shared_informer.go:247] Caches are synced for certificate-csrsigning-kubelet-serving 
2021-04-29T12:20:39.640212779Z  I0429 12:20:39.639935       7 shared_informer.go:247] Caches are synced for certificate-csrsigning-kubelet-client 
2021-04-29T12:20:39.640675481Z  I0429 12:20:39.640581       7 shared_informer.go:247] Caches are synced for certificate-csrsigning-kube-apiserver-client 
2021-04-29T12:20:39.641356090Z  I0429 12:20:39.641123       7 shared_informer.go:247] Caches are synced for certificate-csrsigning-legacy-unknown 
2021-04-29T12:20:39.652285925Z  E0429 12:20:39.652018       7 clusterroleaggregation_controller.go:181] edit failed with : Operation cannot be fulfilled on clusterroles.rbac.authorization.k8s.io "edit": the object has been modified; please apply your changes to the latest version and try again
2021-04-29T12:20:39.659129870Z  E0429 12:20:39.658913       7 clusterroleaggregation_controller.go:181] admin failed with : Operation cannot be fulfilled on clusterroles.rbac.authorization.k8s.io "admin": the object has been modified; please apply your changes to the latest version and try again
2021-04-29T12:20:39.691229824Z  I0429 12:20:39.690904       7 shared_informer.go:247] Caches are synced for ReplicaSet 
2021-04-29T12:20:39.731180774Z  I0429 12:20:39.730964       7 shared_informer.go:247] Caches are synced for stateful set 
2021-04-29T12:20:39.783262768Z  I0429 12:20:39.783042       7 shared_informer.go:247] Caches are synced for endpoint_slice_mirroring 
2021-04-29T12:20:39.788256602Z  I0429 12:20:39.787988       7 shared_informer.go:247] Caches are synced for resource quota 
2021-04-29T12:20:39.791086874Z  I0429 12:20:39.790880       7 shared_informer.go:247] Caches are synced for endpoint 
2021-04-29T12:20:39.813142379Z  I0429 12:20:39.812910       7 shared_informer.go:247] Caches are synced for deployment 
2021-04-29T12:20:39.822411863Z  I0429 12:20:39.822170       7 shared_informer.go:247] Caches are synced for disruption 
2021-04-29T12:20:39.822500213Z  I0429 12:20:39.822205       7 disruption.go:339] Sending events to api server.
2021-04-29T12:20:39.831429217Z  I0429 12:20:39.831217       7 shared_informer.go:247] Caches are synced for resource quota 
2021-04-29T12:20:40.184043594Z  E0429 12:20:40.183850       7 memcache.go:101] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
2021-04-29T12:20:40.189213150Z  I0429 12:20:40.189012       7 shared_informer.go:240] Waiting for caches to sync for garbage collector
2021-04-29T12:20:40.244021282Z  I0429 12:20:40.243739       7 event.go:291] "Event occurred" object="kube-system/helm-install-traefik" kind="Job" apiVersion="batch/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: helm-install-traefik-2vnjc"
2021-04-29T12:20:40.252491635Z  I0429 12:20:40.252280       7 topology_manager.go:187] [topologymanager] Topology Admit Handler
2021-04-29T12:20:40.255351171Z  I0429 12:20:40.255191       7 controller.go:609] quota admission added evaluator for: events.events.k8s.io
2021-04-29T12:20:40.289462152Z  I0429 12:20:40.289280       7 shared_informer.go:247] Caches are synced for garbage collector 
2021-04-29T12:20:40.312844025Z  I0429 12:20:40.312590       7 shared_informer.go:247] Caches are synced for garbage collector 
2021-04-29T12:20:40.312895568Z  I0429 12:20:40.312630       7 garbagecollector.go:151] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
2021-04-29T12:20:40.335011207Z  I0429 12:20:40.334862       7 controller.go:609] quota admission added evaluator for: replicasets.apps
2021-04-29T12:20:40.338412926Z  I0429 12:20:40.338253       7 event.go:291] "Event occurred" object="kube-system/metrics-server" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set metrics-server-86cbb8457f to 1"
2021-04-29T12:20:40.339597723Z  I0429 12:20:40.339440       7 event.go:291] "Event occurred" object="kube-system/coredns" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-854c77959c to 1"
2021-04-29T12:20:40.342163574Z  I0429 12:20:40.341986       7 event.go:291] "Event occurred" object="kube-system/local-path-provisioner" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set local-path-provisioner-5ff76fc89d to 1"
2021-04-29T12:20:40.376334340Z  I0429 12:20:40.375952       7 reconciler.go:224] operationExecutor.VerifyControllerAttachedVolume started for volume "values" (UniqueName: "kubernetes.io/configmap/2d06d630-7d05-40c1-9d42-71aba9aab3cb-values") pod "helm-install-traefik-2vnjc" (UID: "2d06d630-7d05-40c1-9d42-71aba9aab3cb") 
2021-04-29T12:20:40.376433097Z  I0429 12:20:40.376057       7 reconciler.go:224] operationExecutor.VerifyControllerAttachedVolume started for volume "content" (UniqueName: "kubernetes.io/configmap/2d06d630-7d05-40c1-9d42-71aba9aab3cb-content") pod "helm-install-traefik-2vnjc" (UID: "2d06d630-7d05-40c1-9d42-71aba9aab3cb") 
2021-04-29T12:20:40.376594920Z  I0429 12:20:40.376312       7 reconciler.go:224] operationExecutor.VerifyControllerAttachedVolume started for volume "helm-traefik-token-vvdn4" (UniqueName: "kubernetes.io/secret/2d06d630-7d05-40c1-9d42-71aba9aab3cb-helm-traefik-token-vvdn4") pod "helm-install-traefik-2vnjc" (UID: "2d06d630-7d05-40c1-9d42-71aba9aab3cb") 
2021-04-29T12:20:40.440583697Z  I0429 12:20:40.440369       7 event.go:291] "Event occurred" object="kube-system/coredns-854c77959c" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-854c77959c-8x6q9"
2021-04-29T12:20:40.440746289Z  I0429 12:20:40.440625       7 event.go:291] "Event occurred" object="kube-system/metrics-server-86cbb8457f" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: metrics-server-86cbb8457f-st8z7"
2021-04-29T12:20:40.441976135Z  I0429 12:20:40.441767       7 event.go:291] "Event occurred" object="kube-system/local-path-provisioner-5ff76fc89d" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: local-path-provisioner-5ff76fc89d-qr64c"
2021-04-29T12:20:40.451684854Z  I0429 12:20:40.451517       7 topology_manager.go:187] [topologymanager] Topology Admit Handler
2021-04-29T12:20:40.454834233Z  I0429 12:20:40.454643       7 topology_manager.go:187] [topologymanager] Topology Admit Handler
2021-04-29T12:20:40.456245738Z  I0429 12:20:40.456053       7 topology_manager.go:187] [topologymanager] Topology Admit Handler
2021-04-29T12:20:40.476826811Z  I0429 12:20:40.476524       7 reconciler.go:224] operationExecutor.VerifyControllerAttachedVolume started for volume "metrics-server-token-gmsxs" (UniqueName: "kubernetes.io/secret/75dacfba-f604-4765-8a73-d390eb3d6135-metrics-server-token-gmsxs") pod "metrics-server-86cbb8457f-st8z7" (UID: "75dacfba-f604-4765-8a73-d390eb3d6135") 
2021-04-29T12:20:40.476917955Z  I0429 12:20:40.476606       7 reconciler.go:224] operationExecutor.VerifyControllerAttachedVolume started for volume "tmp-dir" (UniqueName: "kubernetes.io/empty-dir/75dacfba-f604-4765-8a73-d390eb3d6135-tmp-dir") pod "metrics-server-86cbb8457f-st8z7" (UID: "75dacfba-f604-4765-8a73-d390eb3d6135") 
2021-04-29T12:20:40.476936812Z  I0429 12:20:40.476638       7 reconciler.go:224] operationExecutor.VerifyControllerAttachedVolume started for volume "config-volume" (UniqueName: "kubernetes.io/configmap/d89fda75-c029-487e-a2a3-fb2dbc64326d-config-volume") pod "coredns-854c77959c-8x6q9" (UID: "d89fda75-c029-487e-a2a3-fb2dbc64326d") 
2021-04-29T12:20:40.476949663Z  I0429 12:20:40.476667       7 reconciler.go:224] operationExecutor.VerifyControllerAttachedVolume started for volume "coredns-token-xhgmr" (UniqueName: "kubernetes.io/secret/d89fda75-c029-487e-a2a3-fb2dbc64326d-coredns-token-xhgmr") pod "coredns-854c77959c-8x6q9" (UID: "d89fda75-c029-487e-a2a3-fb2dbc64326d") 
2021-04-29T12:20:40.476962444Z  I0429 12:20:40.476704       7 reconciler.go:224] operationExecutor.VerifyControllerAttachedVolume started for volume "config-volume" (UniqueName: "kubernetes.io/configmap/7928673b-4d24-44e0-b43e-ca8874c7325c-config-volume") pod "local-path-provisioner-5ff76fc89d-qr64c" (UID: "7928673b-4d24-44e0-b43e-ca8874c7325c") 
2021-04-29T12:20:40.476975575Z  I0429 12:20:40.476741       7 reconciler.go:224] operationExecutor.VerifyControllerAttachedVolume started for volume "local-path-provisioner-service-account-token-5g2pd" (UniqueName: "kubernetes.io/secret/7928673b-4d24-44e0-b43e-ca8874c7325c-local-path-provisioner-service-account-token-5g2pd") pod "local-path-provisioner-5ff76fc89d-qr64c" (UID: "7928673b-4d24-44e0-b43e-ca8874c7325c") 
2021-04-29T12:20:40.786114083Z  time="2021-04-29T12:20:40.785933053Z" level=info msg="Node CIDR assigned for: k3d-default-server-0"
2021-04-29T12:20:40.786199290Z  I0429 12:20:40.786090       7 flannel.go:92] Determining IP address of default interface
2021-04-29T12:20:40.786575109Z  I0429 12:20:40.786472       7 flannel.go:105] Using interface with name eth0 and address 172.27.0.2
2021-04-29T12:20:40.792784331Z  time="2021-04-29T12:20:40.792682571Z" level=info msg="labels have been set successfully on node: k3d-default-server-0"
2021-04-29T12:20:40.794992661Z  I0429 12:20:40.794834       7 kube.go:117] Waiting 10m0s for node controller to sync
2021-04-29T12:20:40.795043785Z  I0429 12:20:40.794921       7 kube.go:300] Starting kube subnet manager
2021-04-29T12:20:40.901231792Z  I0429 12:20:40.901099       7 network_policy_controller.go:138] Starting network policy controller
2021-04-29T12:20:40.912521661Z  I0429 12:20:40.912404       7 network_policy_controller.go:145] Starting network policy controller full sync goroutine
2021-04-29T12:20:41.291458603Z  W0429 12:20:41.291212       7 handler_proxy.go:102] no RequestInfo found in the context
2021-04-29T12:20:41.291503301Z  E0429 12:20:41.291286       7 controller.go:116] loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
2021-04-29T12:20:41.291514825Z  , Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2021-04-29T12:20:41.291552121Z  I0429 12:20:41.291305       7 controller.go:129] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
2021-04-29T12:20:41.795340145Z  I0429 12:20:41.795156       7 kube.go:124] Node controller sync successful
2021-04-29T12:20:41.795482552Z  I0429 12:20:41.795320       7 vxlan.go:121] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=false
2021-04-29T12:20:41.818133460Z  I0429 12:20:41.817954       7 flannel.go:78] Wrote subnet file to /run/flannel/subnet.env
2021-04-29T12:20:41.818240877Z  I0429 12:20:41.817972       7 flannel.go:82] Running backend.
2021-04-29T12:20:41.818265531Z  I0429 12:20:41.817981       7 vxlan_network.go:60] watching for new subnet leases
2021-04-29T12:20:41.819565847Z  I0429 12:20:41.819416       7 iptables.go:145] Some iptables rules are missing; deleting and recreating rules
2021-04-29T12:20:41.819617460Z  I0429 12:20:41.819436       7 iptables.go:167] Deleting iptables rule: -s 10.42.0.0/16 -j ACCEPT
2021-04-29T12:20:41.820207903Z  I0429 12:20:41.820071       7 iptables.go:167] Deleting iptables rule: -d 10.42.0.0/16 -j ACCEPT
2021-04-29T12:20:41.820631424Z  I0429 12:20:41.820483       7 iptables.go:145] Some iptables rules are missing; deleting and recreating rules
2021-04-29T12:20:41.820668580Z  I0429 12:20:41.820518       7 iptables.go:167] Deleting iptables rule: -s 10.42.0.0/16 -d 10.42.0.0/16 -j RETURN
2021-04-29T12:20:41.820774949Z  I0429 12:20:41.820673       7 iptables.go:155] Adding iptables rule: -s 10.42.0.0/16 -j ACCEPT
2021-04-29T12:20:41.821210763Z  I0429 12:20:41.821073       7 iptables.go:167] Deleting iptables rule: -s 10.42.0.0/16 ! -d 224.0.0.0/4 -j MASQUERADE --random-fully
2021-04-29T12:20:41.822025468Z  I0429 12:20:41.821915       7 iptables.go:167] Deleting iptables rule: ! -s 10.42.0.0/16 -d 10.42.0.0/24 -j RETURN
2021-04-29T12:20:41.822404360Z  I0429 12:20:41.822306       7 iptables.go:155] Adding iptables rule: -d 10.42.0.0/16 -j ACCEPT
2021-04-29T12:20:41.823263765Z  I0429 12:20:41.823141       7 iptables.go:167] Deleting iptables rule: ! -s 10.42.0.0/16 -d 10.42.0.0/16 -j MASQUERADE --random-fully
2021-04-29T12:20:41.823905192Z  I0429 12:20:41.823816       7 iptables.go:155] Adding iptables rule: -s 10.42.0.0/16 -d 10.42.0.0/16 -j RETURN
2021-04-29T12:20:41.824744412Z  I0429 12:20:41.824615       7 iptables.go:155] Adding iptables rule: -s 10.42.0.0/16 ! -d 224.0.0.0/4 -j MASQUERADE --random-fully
2021-04-29T12:20:41.826208019Z  I0429 12:20:41.826100       7 iptables.go:155] Adding iptables rule: ! -s 10.42.0.0/16 -d 10.42.0.0/24 -j RETURN
2021-04-29T12:20:41.827478652Z  I0429 12:20:41.827389       7 iptables.go:155] Adding iptables rule: ! -s 10.42.0.0/16 -d 10.42.0.0/16 -j MASQUERADE --random-fully
